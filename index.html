<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Code-Switching Speech Synthesis</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
        }
        h1 {
            color: #333;
        }
        section {
            margin-top: 20px;
            padding: 10px;
            background-color: #f8f8f8;
        }
        article {
            margin-top: 20px;
        }
        footer {
            margin-top: 20px;
            text-align: center;
            font-size: 0.9em;
            color: #666;
        }
    </style>
</head>
<body>
    <header>
        <h1>Code-switching Speech Synthesis for Mandarin-English using a Unified IPA-based Approach with FastSpeech2</h1>
    </header>
    <section>
        <h2>Overview</h2>
        <p>This research explores two main methods for synthesizing natural-sounding code-switched speech between Mandarin and English using the FastSpeech2 model:</p>
        <ul>
            <li><strong>Method 1:</strong> Modeling the phonemes of Mandarin and English separately, which involved handling alignment with the Montreal Forced Aligner and developing a mixed dictionary and acoustic model.</li>
            <li><strong>Method 2:</strong> Unifying the input formats for both languages as phonological features based on the International Phonetic Alphabet (IPA), implemented using the <a href="https://github.com/IMS-Toucan">IMS-Toucan</a> GitHub repository. </li>
        </ul>
    </section>
    <section>
        <h2>Experimental Setup</h2>
        <article>
            <h3>Method 1</h3>
            <p>For Method 1, three sets of experiments were conducted:</p>
            <ol>
                <li>Group A: Pre-training on a code-switched Mandarin-English dataset for ASR tasks, then fine-tuning with 500 high-quality code-switched Mandarin-English audios.</li>
                <li>Group B: Pre-training on a dataset for Mandarin TTS tasks, followed by fine-tuning using the 500 code-switched audios.</li>
                <li>Group C: Pre-training on a dataset for Mandarin TTS tasks, followed by fine-tuning with an English TTS dataset.</li>
            </ol>
        </article>
        <article>
            <h3>Method 2 (Group D)</h3>
            <p>The unified IPA-based approach was implemented using the IMS-Toucan repository, with the pre-trained model fine-tuned on only 500 high-quality mixed Mandarin-English sentences.</p>
        </article>
    </section>
    <footer>
        <p>For the unified IPA-based approach (Method 2/Group D), the input formats for both Mandarin and English were represented as phonological features based on the IPA. This method was implemented using the <a href="https://github.com/IMS-Toucan">IMS-Toucan</a> GitHub repository, with the pre-trained model fine-tuned on only 500 high-quality mixed Mandarin-English sentences.</p>
    </footer>
</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audio Samples</title>
    <style>
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #ccc;
            padding: 8px;
            text-align: center;
            vertical-align: middle;
        }
        th {
            background-color: #f2f2f2;
        }
        audio {
            width: 100%;
        }
    </style>
</head>
<body>
    <table>
        <tr>
            <th>Groups / Sentences</th>
            <th>Tiktok是最近非常热门的一款APP。</th>
            <th>我对这个topic很感兴趣。</th>
            <th>没关系，也许之后能有更好的chance。</th>
        </tr>
        <tr>
            <th>Group A</th>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20A/1.wav?raw=true" type="audio/wav"></audio></td>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20A/2.wav?raw=true" type="audio/wav"></audio></td>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20A/3.wav?raw=true" type="audio/wav"></audio></td>
        </tr>
        <tr>
            <th>Group B</th>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20B/1.wav?raw=true" type="audio/wav"></audio></td>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20B/2.wav?raw=true" type="audio/wav"></audio></td>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20B/3.wav?raw=true" type="audio/wav"></audio></td>
        </tr>
        <tr>
            <th>Group C</th>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20C/1.wav?raw=true" type="audio/wav"></audio></td>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20C/2.wav?raw=true" type="audio/wav"></audio></td>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20C/3.wav?raw=true" type="audio/wav"></audio></td>
        </tr>
        <tr>
            <th>Group D</th>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20D/1.wav?raw=true" type="audio/wav"></audio></td>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20D/2.wav?raw=true" type="audio/wav"></audio></td>
            <td><audio controls><source src="https://github.com/WANGYINQIU/Mandarin_and_English_CS_TTS/blob/main/audios/Group%20D/3.wav?raw=true" type="audio/wav"></audio></td>
        </tr>
    </table>
</body>
</html>
<h2><strong>Relevance: </strong>Successful development of code-switching TTS systems can facilitate communication across languages, with applications in education, media, and assistive technologies for enhancing accessibility in multilingual societies.</h2>
